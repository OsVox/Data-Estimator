{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ejWFL29Ivid_jEpn36yMI_RnTv7gViRT",
      "authorship_tag": "ABX9TyP6ir2eQutha2A4psFid9De",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OsVox/Data-Estimator/blob/main/Image_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import modules and files"
      ],
      "metadata": {
        "id": "qaga88A3_wq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "zp4tGZKTaqlJ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT = '/content/drive/MyDrive/images/'\n",
        "\n",
        "def save(what, where):\n",
        "    what.to_csv(ROOT + where + '.csv', index=False)"
      ],
      "metadata": {
        "id": "3uE9K0q9o3AK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annotations = pd.read_csv(ROOT + 'annotations.csv')\n",
        "part_ann = pd.read_csv(ROOT + 'part_ann.csv')"
      ],
      "metadata": {
        "id": "-_x2pE74rBOc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget http://images.cocodataset.org/zips/train2017.zip\n",
        "# !unzip annotations_trainval2017.zip\n",
        "\n",
        "# train = sorted(os.listdir('train2017'))\n",
        "\n",
        "# shape_1 = []\n",
        "# shape_2 = []\n",
        "\n",
        "# for image_name in train:\n",
        "#     Image = cv2.imread('/content/train2017/{}'.format(image_name))\n",
        "#     Image = cv2.cvtColor(Image, cv2.COLOR_BGR2RGB)\n",
        "#     shape_1.append(Image.shape[0])\n",
        "#     shape_2.append"
      ],
      "metadata": {
        "id": "LuiOvIcBJKNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kx3qZVdEc1E",
        "outputId": "3b47a014-55c7-4dee-dff6-6b10c7811c99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-14 15:58:13--  http://images.cocodataset.org/zips/train2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.217.168.41\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.217.168.41|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19336861798 (18G) [application/zip]\n",
            "Saving to: ‘train2017.zip’\n",
            "\n",
            "train2017.zip       100%[===================>]  18.01G  48.0MB/s    in 6m 39s  \n",
            "\n",
            "2022-03-14 16:04:52 (46.2 MB/s) - ‘train2017.zip’ saved [19336861798/19336861798]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !wget http://images.cocodataset.org/zips/train2017.zip\n",
        "# !wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "# ! unzip annotations_trainval2017.zip\n",
        "\n",
        "# f = open('annotations/captions_train2017.json')\n",
        "# data = json.load(f)\n",
        "# train = sorted(os.listdir('train2017'))[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating annotations"
      ],
      "metadata": {
        "id": "38cKKaPx_1Pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_id = []\n",
        "captions = []\n",
        "\n",
        "for caption in data['annotations']:\n",
        "    image_id.append(caption['image_id'])\n",
        "    captions.append(caption['caption'])\n",
        "\n",
        "annotations = pd.DataFrame({'image_id':image_id, 'caption':captions})"
      ],
      "metadata": {
        "id": "vQKgtk_PbSST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter = annotations.groupby('image_id').count()\n",
        "\n",
        "for value in [6, 7]:\n",
        "    for ind in counter[counter['caption'] == value].index:\n",
        "        indecies = annotations[annotations['image_id'] == ind].index[5:]\n",
        "        annotations.drop(index=indecies, inplace=True)\n",
        "\n",
        "annotations.sort_values(by='image_id', inplace=True)"
      ],
      "metadata": {
        "id": "0U0yGPkEf73O"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keep only 1000 pictures for building code"
      ],
      "metadata": {
        "id": "85y7Jsmcrnhi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing images"
      ],
      "metadata": {
        "id": "WQ89XEcPYMy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for image_name in train:\n",
        "    Image = cv2.imread('/content/train2017/{}'.format(image_name))\n",
        "    Image = cv2.cvtColor(Image, cv2.COLOR_BGR2RGB)\n",
        "    np.save('/content/drive/MyDrive/images/part_img/{}'.format(image_name[:-4]), Image)"
      ],
      "metadata": {
        "id": "Z9TLPhwb5VNC"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessing = tf.keras.applications.inception_v3.preprocess_input\n",
        "\n",
        "for image_name in os.listdir('/content/drive/MyDrive/images/images'):\n",
        "\n",
        "    im = Image.fromarray(np.load('/content/drive/MyDrive/images/images/{}'.format(image_name))).resize((299, 299))\n",
        "    array = preprocessing(np.array(im))\n",
        "    np.save('/content/drive/MyDrive/images/images/{}'.format(image_name), array)"
      ],
      "metadata": {
        "id": "3VokfNSsuXCv"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing test"
      ],
      "metadata": {
        "id": "H9r8XpTdYPx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Uehq3tQZYWH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZWNcl2AmYYJ4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}